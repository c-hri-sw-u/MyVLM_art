{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¨ MyVLM-Art æ¦‚å¿µåµŒå…¥è®­ç»ƒ\n",
        "\n",
        "åœ¨ Google Colab ä¸Šè®­ç»ƒæ¦‚å¿µåµŒå…¥æ¨¡å‹ã€‚\n",
        "\n",
        "âš ï¸ **è¦æ±‚**: GPU è¿è¡Œæ—¶ (T4 æˆ–æ›´é«˜)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. æ£€æŸ¥ GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# æ£€æŸ¥ CUDA ç‰ˆæœ¬\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å®‰è£…ä¾èµ– (ä¿®å¤ bitsandbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¸è½½æ—§ç‰ˆæœ¬ bitsandbytes\n",
        "!pip uninstall -y bitsandbytes\n",
        "\n",
        "# å®‰è£…å…¼å®¹ Colab CUDA 12.x çš„ bitsandbytes\n",
        "!pip install bitsandbytes>=0.41.0 --no-cache-dir\n",
        "\n",
        "# éªŒè¯ bitsandbytes å®‰è£…\n",
        "!python -m bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# å®‰è£…å…¶ä»–ä¾èµ–\n",
        "!pip install accelerate>=0.28.0\n",
        "!pip install transformers>=4.37.2\n",
        "!pip install peft>=0.2.0\n",
        "!pip install open-clip-torch\n",
        "!pip install timm>=0.9.16\n",
        "!pip install sentence-transformers>=2.3.1\n",
        "!pip install omegaconf>=2.3.0\n",
        "!pip install pyrallis>=0.3.1\n",
        "!pip install loguru>=0.7.0\n",
        "!pip install wandb>=0.16.0  # wandb for training logging\n",
        "print(\"âœ… ä¾èµ–å®‰è£…å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# é‡å¯ runtime ä»¥åº”ç”¨ bitsandbytes (å¿…é¡»!)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "âš ï¸ **é‡å¯åä»è¿™é‡Œç»§ç»­** â¬‡ï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# éªŒè¯ bitsandbytes æ­£å¸¸å·¥ä½œ\n",
        "import bitsandbytes as bnb\n",
        "print(f\"âœ… bitsandbytes ç‰ˆæœ¬: {bnb.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clone ä»£ç ä»“åº“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# TODO: æ›¿æ¢ä¸ºä½ çš„ GitHub ä»“åº“åœ°å€\n",
        "REPO_URL = \"https://github.com/YOUR_USERNAME/MyVLM_art.git\"\n",
        "\n",
        "# å¦‚æœæ˜¯ç§æœ‰ä»“åº“ï¼Œä½¿ç”¨ token\n",
        "# REPO_URL = \"https://<TOKEN>@github.com/YOUR_USERNAME/MyVLM_art.git\"\n",
        "\n",
        "if not os.path.exists(\"/content/MyVLM_art\"):\n",
        "    !git clone {REPO_URL}\n",
        "    \n",
        "os.chdir(\"/content/MyVLM_art\")\n",
        "print(f\"ğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (å¤‡é€‰) ä» Google Drive å¤åˆ¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¦‚æœä»£ç åœ¨ Google Drive ä¸Šï¼Œè¿è¡Œè¿™ä¸ª cell\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r \"/content/drive/MyDrive/MyVLM_art\" /content/\n",
        "# import os\n",
        "# os.chdir(\"/content/MyVLM_art\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. éªŒè¯æ–‡ä»¶ç»“æ„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# æ£€æŸ¥å¿…è¦æ–‡ä»¶\n",
        "required_files = [\n",
        "    \"artifacts/prototypes_artist_trained.pt\",\n",
        "    \"artifacts/prototypes_style_trained.pt\",\n",
        "    \"artifacts/prototypes_genre_trained.pt\",\n",
        "    \"artifacts/concept_signals_artist.json\",\n",
        "    \"artifacts/concept_signals_style.json\",\n",
        "    \"artifacts/concept_signals_genre.json\",\n",
        "    \"artifacts/synth_targets.csv\",\n",
        "    \"data/dataset/wikiart_5artists_dataset.json\",\n",
        "]\n",
        "\n",
        "print(\"ğŸ“ æ£€æŸ¥å¿…è¦æ–‡ä»¶:\")\n",
        "all_exist = True\n",
        "for f in required_files:\n",
        "    exists = Path(f).exists()\n",
        "    status = \"âœ…\" if exists else \"âŒ\"\n",
        "    print(f\"  {status} {f}\")\n",
        "    if not exists:\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\nâœ… æ‰€æœ‰æ–‡ä»¶å°±ç»ª!\")\n",
        "else:\n",
        "    print(\"\\nâŒ ç¼ºå°‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä»“åº“\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.5 é…ç½® Wandb (å¯é€‰)\n",
        "\n",
        "è®¾ç½® wandb API key ä»¥ç›‘æ§è®­ç»ƒ lossã€‚å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼è®¾ç½®ï¼š\n",
        "1. **ç¯å¢ƒå˜é‡** `WANDB_API_KEY` (æ¨è)\n",
        "2. åœ¨ `~/.wandb_api_key` æ–‡ä»¶ä¸­å†™å…¥ key\n",
        "3. ç›´æ¥åœ¨ config ä¸­ä¼ å…¥ `wandb_api_key`\n",
        "\n",
        "è·å– API key: https://wandb.ai/authorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# æ–¹æ³• 1: ä»ç¯å¢ƒå˜é‡è®¾ç½® (æ¨èåœ¨ Colab Secrets ä¸­è®¾ç½®)\n",
        "# åœ¨ Colab å·¦ä¾§ç‚¹å‡» ğŸ”‘ å›¾æ ‡ï¼Œæ·»åŠ  Secret: WANDB_API_KEY\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_API_KEY')\n",
        "    print(\"âœ… Wandb API key å·²ä» Colab Secrets è¯»å–\")\n",
        "except:\n",
        "    print(\"âš ï¸ æœªåœ¨ Colab Secrets ä¸­æ‰¾åˆ° WANDB_API_KEY\")\n",
        "\n",
        "# æ–¹æ³• 2: æ‰‹åŠ¨è®¾ç½® (ä¸æ¨èï¼Œä¸è¦æäº¤åˆ° Git)\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# æ–¹æ³• 3: å†™å…¥æ–‡ä»¶ (åœ¨æœ¬åœ°è¿è¡Œæ—¶å¯ç”¨)\n",
        "# from pathlib import Path\n",
        "# (Path.home() / \".wandb_api_key\").write_text(\"your-api-key-here\")\n",
        "\n",
        "# éªŒè¯ wandb å®‰è£…\n",
        "try:\n",
        "    import wandb\n",
        "    print(f\"âœ… wandb ç‰ˆæœ¬: {wandb.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"âŒ wandb æœªå®‰è£…ï¼Œè¿è¡Œ: pip install wandb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. è¿è¡Œè®­ç»ƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç›´æ¥è¿è¡Œè®­ç»ƒè„šæœ¬\n",
        "!python concept_graph/concept_embeddings/train_concept_embedding.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (å¯é€‰) è‡ªå®šä¹‰å‚æ•°è¿è¡Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¦‚æœéœ€è¦è°ƒæ•´å‚æ•°ï¼Œå¯ä»¥ç›´æ¥åœ¨è¿™é‡Œè¿è¡Œ\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/MyVLM_art\")\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from myvlm.common import VLMType, PersonalizationTask, VLM_TO_LAYER\n",
        "from configs.myvlm_art_config import MyVLMArtConfig\n",
        "from vlms.llava_wrapper import LLaVAWrapper\n",
        "from myvlm.myllava import MyLLaVA\n",
        "from concept_graph.concept_embeddings.trainer import MultiTokenEmbeddingTrainer\n",
        "\n",
        "# å¯ä»¥è°ƒæ•´çš„å‚æ•°\n",
        "cfg = MyVLMArtConfig(\n",
        "    concept_name=\"dataset\",\n",
        "    concept_identifier=\"painting\",\n",
        "    vlm_type=VLMType.LLAVA,\n",
        "    personalization_task=PersonalizationTask.CAPTIONING,\n",
        "    output_root=Path(\"./outputs\"),\n",
        "    data_root=Path(\"./data\"),\n",
        "    optimization_steps=100,       # è®­ç»ƒæ­¥æ•°\n",
        "    learning_rate=1.0,\n",
        "    batch_size=4,                 # æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ (T4 å»ºè®® 2-4)\n",
        "    reg_lambda=0.0075,\n",
        "    device='cuda',\n",
        "    torch_dtype=torch.float16,\n",
        "    threshold=0.75,\n",
        "    max_tokens_per_concept=6,\n",
        "    max_concepts_per_sample=3,\n",
        "    backoff_delta=0.05,\n",
        "    val_subset_n=3,\n",
        "    max_reason_tokens=64,\n",
        "    grad_accum_steps=4,\n",
        "    attn_reg_interval=4,\n",
        "    # Wandb é…ç½® (ä»ç¯å¢ƒå˜é‡è¯»å– keyï¼Œæ— éœ€åœ¨æ­¤è®¾ç½®)\n",
        "    use_wandb=True,                          # å¯ç”¨ wandb æ—¥å¿—\n",
        "    wandb_project=\"myvlm-art-training\",      # wandb é¡¹ç›®å\n",
        "    wandb_run_name=None,                     # ç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ\n",
        ")\n",
        "\n",
        "print(\"ğŸ”„ åŠ è½½ LLaVA æ¨¡å‹...\")\n",
        "vlm = LLaVAWrapper(device=cfg.device, torch_dtype=cfg.torch_dtype)\n",
        "\n",
        "print(\"ğŸ”§ åˆå§‹åŒ– MyLLaVA...\")\n",
        "myvlm = MyLLaVA(vlm, layer=VLM_TO_LAYER[cfg.vlm_type], concept_name=cfg.concept_name, cfg=cfg)\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "trainer = MultiTokenEmbeddingTrainer(cfg=cfg, myvlm=myvlm, dataset_builder=None)\n",
        "checkpoints = trainer.train()\n",
        "\n",
        "# ä¿å­˜\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "out_dir = cfg.output_root / cfg.concept_name / f\"seed_{cfg.seed}\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "ts = datetime.now(ZoneInfo('America/New_York')).strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = out_dir / f\"checkpoints_{cfg.concept_name}_seed_{cfg.seed}_{ts}.pt\"\n",
        "torch.save(checkpoints, save_path)\n",
        "print(f\"\\nğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æŸ¥çœ‹è®­ç»ƒç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "output_dir = Path(\"outputs/dataset/seed_42\")\n",
        "ckpts = sorted(output_dir.glob(\"checkpoints_*.pt\"))\n",
        "\n",
        "if ckpts:\n",
        "    latest = ckpts[-1]\n",
        "    print(f\"ğŸ“¦ æœ€æ–°æ£€æŸ¥ç‚¹: {latest}\")\n",
        "    \n",
        "    data = torch.load(latest, map_location=\"cpu\")\n",
        "    print(f\"ğŸ“Š åŒ…å« {len(data)} ä¸ªè¿­ä»£çš„æ£€æŸ¥ç‚¹\")\n",
        "    \n",
        "    for k, v in data.items():\n",
        "        if isinstance(v, dict):\n",
        "            keys_shape = v.get('keys', torch.tensor([])).shape\n",
        "            values_shape = v.get('values', torch.tensor([])).shape\n",
        "            print(f\"  è¿­ä»£ {k}: keys={keys_shape}, values={values_shape}\")\n",
        "else:\n",
        "    print(\"âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ä¿å­˜åˆ° Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# å¤åˆ¶è¾“å‡ºæ–‡ä»¶\n",
        "save_dir = Path(\"/content/drive/MyDrive/MyVLM_art_outputs\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shutil.copytree(\"outputs\", save_dir / \"outputs\", dirs_exist_ok=True)\n",
        "print(f\"âœ… å·²ä¿å­˜åˆ°: {save_dir / 'outputs'}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
