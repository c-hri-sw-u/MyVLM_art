{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¨ MyVLM-Art è®­ç»ƒ (Clean Version)\n",
        "\n",
        "âš ï¸ **è¦æ±‚**: GPU è¿è¡Œæ—¶ (T4 æˆ–æ›´é«˜)\n",
        "\n",
        "**è¿è¡Œé¡ºåº**:\n",
        "1. è¿è¡Œ Cell 1 (å®‰è£…ä¾èµ–)\n",
        "2. è¿è¡Œ Cell 2 (é‡å¯ - ä¼šè‡ªåŠ¨é‡å¯)\n",
        "3. **é‡å¯å** ä» Cell 3 å¼€å§‹è¿è¡Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: å®‰è£…ä¾èµ–\n",
        "\n",
        "âš ï¸ è¿è¡Œå®Œåå¿…é¡»é‡å¯ Runtimeï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# å®Œå…¨å¸è½½æ—§ç‰ˆæœ¬\n",
        "!pip uninstall -y bitsandbytes transformers accelerate -q\n",
        "\n",
        "# å®‰è£…å›ºå®šç‰ˆæœ¬\n",
        "!pip install transformers==4.36.2 --no-cache-dir -q\n",
        "!pip install accelerate==0.25.0 --no-cache-dir -q\n",
        "!pip install bitsandbytes==0.41.3 --no-cache-dir -q\n",
        "!pip install peft>=0.2.0 -q\n",
        "!pip install open-clip-torch -q\n",
        "!pip install timm>=0.9.16 -q\n",
        "!pip install sentence-transformers>=2.3.1 -q\n",
        "!pip install omegaconf>=2.3.0 -q\n",
        "!pip install pyrallis>=0.3.1 -q\n",
        "!pip install loguru>=0.7.0 -q\n",
        "!pip install wandb>=0.16.0 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"âœ… ä¾èµ–å®‰è£…å®Œæˆ\")\n",
        "print(\"âš ï¸ ç°åœ¨è¿è¡Œä¸‹ä¸€ä¸ª Cell é‡å¯ Runtime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: é‡å¯ Runtime\n",
        "\n",
        "âš ï¸ **è¿è¡Œåè‡ªåŠ¨é‡å¯ï¼Œé‡å¯åè·³è¿‡ Cell 1-2ï¼Œç›´æ¥ä» Cell 3 å¼€å§‹**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# â¬‡ï¸â¬‡ï¸â¬‡ï¸ é‡å¯åä»è¿™é‡Œå¼€å§‹ â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: éªŒè¯ç¯å¢ƒ + Clone ä»£ç "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# éªŒè¯ç‰ˆæœ¬\n",
        "import torch\n",
        "import transformers\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# æ£€æŸ¥ç‰ˆæœ¬\n",
        "assert transformers.__version__.startswith(\"4.36\"), f\"transformers ç‰ˆæœ¬åº”ä¸º 4.36.xï¼Œå½“å‰: {transformers.__version__}\"\n",
        "print(\"\\nâœ… ç¯å¢ƒéªŒè¯é€šè¿‡\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5b: åªæµ‹è¯• Stage Bï¼ˆä» checkpoint æ¢å¤ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== åªæµ‹è¯• Stage Bï¼ˆä» checkpoint æ¢å¤ï¼‰ ====================\n",
        "# âš ï¸ å‰æï¼šä¹‹å‰å·²ç»è¿è¡Œè¿‡ Cell 5 å®Œæˆäº†è®­ç»ƒï¼Œcheckpoint åœ¨æœ¬åœ°\n",
        "# âš ï¸ å¦‚æœ runtime å·²æ–­å¼€é‡è¿ï¼Œéœ€è¦å…ˆä» Google Drive æ¢å¤æ–‡ä»¶\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "os.chdir(\"/content/MyVLM_art\")\n",
        "sys.path.insert(0, \"/content/MyVLM_art\")\n",
        "\n",
        "# æ¸…é™¤æ¨¡å—ç¼“å­˜\n",
        "modules_to_clear = [m for m in list(sys.modules.keys()) \n",
        "                    if any(x in m for x in ['vlms', 'myvlm', 'concept_graph', 'configs'])]\n",
        "for m in modules_to_clear:\n",
        "    del sys.modules[m]\n",
        "\n",
        "import torch\n",
        "from myvlm.common import VLMType, PersonalizationTask, VLM_TO_LAYER, MyVLMLayerMode\n",
        "from configs.myvlm_art_config import MyVLMArtConfig\n",
        "from vlms.llava_wrapper import LLaVAWrapper\n",
        "from myvlm.myllava import MyLLaVA\n",
        "from concept_graph.concept_embeddings.trainer import MultiTokenEmbeddingTrainer\n",
        "from myvlm.utils import parent_module, brackets_to_periods\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ========== è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ checkpoint ==========\n",
        "checkpoint_dir = Path(\"/content/MyVLM_art/outputs/dataset/seed_42\")\n",
        "checkpoints = sorted(checkpoint_dir.glob(\"checkpoints_*.pt\"))\n",
        "\n",
        "if checkpoints:\n",
        "    CHECKPOINT_PATH = str(checkpoints[-1])  # æœ€æ–°çš„\n",
        "    print(f\"ğŸ“‚ æ‰¾åˆ° {len(checkpoints)} ä¸ª checkpoint\")\n",
        "    print(f\"ğŸ“¥ ä½¿ç”¨æœ€æ–°çš„: {CHECKPOINT_PATH}\")\n",
        "else:\n",
        "    # æ‰‹åŠ¨æŒ‡å®šè·¯å¾„\n",
        "    CHECKPOINT_PATH = \"outputs/dataset/seed_42/checkpoints_dataset_seed_42_20251206_205955.pt\"\n",
        "    print(f\"âš ï¸ æœªæ‰¾åˆ° checkpointï¼Œä½¿ç”¨æŒ‡å®šè·¯å¾„: {CHECKPOINT_PATH}\")\n",
        "\n",
        "cfg = MyVLMArtConfig(\n",
        "    concept_name=\"dataset\",\n",
        "    concept_identifier=\"test\",\n",
        "    vlm_type=VLMType.LLAVA,\n",
        "    personalization_task=PersonalizationTask.CAPTIONING,\n",
        "    output_root=Path(\"./outputs\"),\n",
        "    data_root=Path(\"./data\"),\n",
        "    optimization_steps=1,\n",
        "    learning_rate=1.0,\n",
        "    batch_size=1,\n",
        "    reg_lambda=0.0,\n",
        "    device='cuda',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    threshold=0.75,\n",
        "    max_tokens_per_concept=1,\n",
        "    max_concepts_per_sample=1,\n",
        "    backoff_delta=0.05,\n",
        "    val_subset_n=3,\n",
        "    max_reason_tokens=64,\n",
        "    use_wandb=True,\n",
        "    wandb_project=\"myvlm-art-test\",\n",
        "    wandb_run_name=\"stage-b-only-test\",\n",
        ")\n",
        "\n",
        "# ========== åŠ è½½æ¨¡å‹ ==========\n",
        "print(\"ğŸ”„ åŠ è½½ LLaVA æ¨¡å‹...\")\n",
        "vlm = LLaVAWrapper(device=cfg.device, torch_dtype=cfg.torch_dtype)\n",
        "\n",
        "print(\"ğŸ”§ åˆå§‹åŒ– MyLLaVA...\")\n",
        "myvlm = MyLLaVA(vlm, layer=VLM_TO_LAYER[cfg.vlm_type], concept_name=cfg.concept_name, cfg=cfg)\n",
        "\n",
        "# ========== åˆå§‹åŒ– Trainerï¼ˆä¼šåˆ›å»ºæ•°æ®é›†å’Œæ³¨å…¥å±‚ï¼‰ ==========\n",
        "print(\"ğŸ“¦ åˆå§‹åŒ– Trainer...\")\n",
        "trainer = MultiTokenEmbeddingTrainer(cfg=cfg, myvlm=myvlm, dataset_builder=None)\n",
        "\n",
        "# ========== åŠ è½½ checkpoint åˆ°æ³¨å…¥å±‚ ==========\n",
        "print(f\"ğŸ“¥ åŠ è½½ checkpoint: {CHECKPOINT_PATH}\")\n",
        "ckpt = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
        "# è·å–æœ€æ–°çš„ checkpoint çŠ¶æ€\n",
        "latest_step = max(ckpt.keys())\n",
        "state = ckpt[latest_step]\n",
        "print(f\"  - åŠ è½½ step {latest_step} çš„çŠ¶æ€\")\n",
        "print(f\"  - keys shape: {state.get('keys', torch.tensor([])).shape}\")\n",
        "print(f\"  - values shape: {state.get('values', torch.tensor([])).shape}\")\n",
        "\n",
        "# æ³¨å…¥åˆ°å±‚ä¸­\n",
        "layer = trainer._injected_layer\n",
        "print(f\"  - _injected_layer: {layer}\")\n",
        "print(f\"  - 'values' in state: {'values' in state}\")\n",
        "if layer is not None and 'values' in state:\n",
        "    layer.values = torch.nn.Parameter(state['values'].to(cfg.device, cfg.torch_dtype))\n",
        "    if 'keys' in state and state['keys'].numel() > 0:\n",
        "        layer.keys = state['keys'].to(cfg.device, cfg.torch_dtype)\n",
        "    print(\"âœ… Checkpoint å·²åŠ è½½åˆ°æ¨¡å‹\")\n",
        "    print(f\"  - layer.values shape: {layer.values.shape if layer.values is not None else 'None'}\")\n",
        "else:\n",
        "    print(\"âŒ æ— æ³•åŠ è½½ checkpoint\")\n",
        "    print(f\"  - layer is None: {layer is None}\")\n",
        "    print(f\"  - 'values' in state: {'values' in state}\")\n",
        "\n",
        "# ========== åªè¿è¡Œ Stage B ==========\n",
        "print(\"\\nğŸš€ å¼€å§‹ Stage B æµ‹è¯•...\")\n",
        "\n",
        "# åˆå§‹åŒ– wandb\n",
        "wandb.init(\n",
        "    project=cfg.wandb_project,\n",
        "    name=cfg.wandb_run_name,\n",
        "    config={\"test_type\": \"stage_b_only\", \"checkpoint\": CHECKPOINT_PATH},\n",
        ")\n",
        "\n",
        "# è®¾ç½®è®­ç»ƒæ¨¡å¼\n",
        "setattr(eval(f\"myvlm.vlm.{myvlm.layer}\"), \"training\", True)\n",
        "setattr(eval(f\"myvlm.vlm.{myvlm.layer}\"), \"mode\", MyVLMLayerMode.TRAIN)\n",
        "\n",
        "# åˆ›å»º optimizer\n",
        "optimizer = torch.optim.AdamW(myvlm.vlm.model.parameters(), lr=cfg.learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, cfg.learning_rate)\n",
        "\n",
        "# è¿è¡Œ Stage B\n",
        "dl_b = trainer._train_loaders[\"B\"]\n",
        "print(f\"[Stage B] æ•°æ®é›†å¤§å°: {len(dl_b.dataset)}\")\n",
        "\n",
        "global_step = 0\n",
        "for batch_idx, batch in enumerate(tqdm(dl_b, desc=\"Stage B\")):\n",
        "    if batch_idx >= 5:  # åªæµ‹è¯• 5 ä¸ª batch\n",
        "        break\n",
        "    \n",
        "    # ========== è¯Šæ–­ï¼šæ£€æŸ¥ batch å†…å®¹ ==========\n",
        "    labels = batch.get(\"labels\")\n",
        "    input_ids = batch.get(\"input_ids\")\n",
        "    \n",
        "    if labels is not None:\n",
        "        # ç»Ÿè®¡æœ‰æ•ˆ tokenï¼ˆé -100ï¼‰\n",
        "        valid_tokens = (labels != -100).sum().item()\n",
        "        total_tokens = labels.numel()\n",
        "        print(f\"\\n  [Batch {batch_idx}] è¯Šæ–­:\")\n",
        "        print(f\"    - labels shape: {labels.shape}\")\n",
        "        print(f\"    - æœ‰æ•ˆ token æ•°: {valid_tokens} / {total_tokens}\")\n",
        "        print(f\"    - labels å‰ 20 ä¸ªå€¼: {labels[0, :20].tolist()}\")\n",
        "        print(f\"    - labels å 20 ä¸ªå€¼: {labels[0, -20:].tolist()}\")\n",
        "        \n",
        "        if valid_tokens == 0:\n",
        "            print(f\"    âš ï¸ æ‰€æœ‰ labels éƒ½æ˜¯ -100ï¼è¿™å°±æ˜¯ loss=0 çš„åŸå› ï¼\")\n",
        "    \n",
        "    with torch.cuda.amp.autocast():\n",
        "        outputs = myvlm.vlm.model(**batch)\n",
        "    \n",
        "    loss = outputs.loss\n",
        "    raw_loss = loss.item() if hasattr(loss, 'item') else float(loss)\n",
        "    \n",
        "    # ========== æ·±åº¦è¯Šæ–­ ==========\n",
        "    print(f\"    - loss = {raw_loss:.6f} (raw: {raw_loss:.2e})\")\n",
        "    print(f\"    - loss type: {type(loss)}, dtype: {loss.dtype if hasattr(loss, 'dtype') else 'N/A'}\")\n",
        "    \n",
        "    # æ£€æŸ¥ logits\n",
        "    if hasattr(outputs, 'logits') and outputs.logits is not None:\n",
        "        logits = outputs.logits\n",
        "        print(f\"    - logits shape: {logits.shape}\")\n",
        "        print(f\"    - logits èŒƒå›´: [{logits.min().item():.4f}, {logits.max().item():.4f}]\")\n",
        "        \n",
        "        # æ£€æŸ¥ labels æ˜¯å¦åœ¨ outputs ä¸­è¢«æ‰©å±•\n",
        "        if hasattr(outputs, 'labels') and outputs.labels is not None:\n",
        "            print(f\"    - outputs.labels shape: {outputs.labels.shape}\")\n",
        "        \n",
        "        # æ³¨æ„ï¼šLLaVA ä¼šæŠŠå›¾åƒå±•å¼€æˆ patch tokensï¼Œæ‰€ä»¥ logits æ¯” labels é•¿\n",
        "        # ä¸èƒ½ç›´æ¥æ‰‹åŠ¨è®¡ç®— lossï¼Œéœ€è¦ä¾èµ–æ¨¡å‹å†…éƒ¨çš„ loss è®¡ç®—\n",
        "        print(f\"    âš ï¸ logits ({logits.shape[1]}) vs labels ({labels.shape[1]}) é•¿åº¦ä¸åŒ¹é…ï¼\")\n",
        "        print(f\"    è¿™æ˜¯å› ä¸º LLaVA æŠŠå›¾åƒå±•å¼€æˆäº† {logits.shape[1] - labels.shape[1]} ä¸ª patch tokens\")\n",
        "    else:\n",
        "        print(f\"    - âš ï¸ outputs æ²¡æœ‰ logits å±æ€§\")\n",
        "    \n",
        "    # wandb æ—¥å¿—\n",
        "    wandb.log({\n",
        "        \"stage\": \"B\",\n",
        "        \"batch\": batch_idx,\n",
        "        \"train/loss\": raw_loss,\n",
        "        \"train/loss_log10\": torch.log10(torch.tensor(max(raw_loss, 1e-10))).item(),\n",
        "    }, step=global_step)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    global_step += 1\n",
        "\n",
        "wandb.finish()\n",
        "print(\"\\nâœ… Stage B æµ‹è¯•å®Œæˆ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5c: å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆä¿®å¤åï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== ä¸­ç­‰è§„æ¨¡è®­ç»ƒæµ‹è¯• ====================\n",
        "# âš ï¸ å¦‚æœä¹‹å‰è¿è¡Œè¿‡å…¶ä»–æµ‹è¯•ï¼Œéœ€è¦é‡æ–°åŠ è½½æ¨¡å‹\n",
        "# é¢„è®¡æ—¶é—´ï¼š5-10 åˆ†é’Ÿ\n",
        "\n",
        "import sys\n",
        "import os\n",
        "os.chdir(\"/content/MyVLM_art\")\n",
        "\n",
        "# æ¸…é™¤æ‰€æœ‰ç›¸å…³æ¨¡å—ç¼“å­˜\n",
        "modules_to_clear = [m for m in list(sys.modules.keys()) \n",
        "                    if any(x in m for x in ['vlms', 'myvlm', 'concept_graph', 'configs'])]\n",
        "for m in modules_to_clear:\n",
        "    del sys.modules[m]\n",
        "print(f\"âœ… æ¸…é™¤ {len(modules_to_clear)} ä¸ªæ¨¡å—ç¼“å­˜\")\n",
        "\n",
        "# ========== åº”ç”¨å…¼å®¹æ€§ Patch ==========\n",
        "# Patch 1: é‡åŒ–é…ç½®å†²çª\n",
        "import vlms.llava.model.builder as builder_module\n",
        "_orig_load = builder_module.load_pretrained_model\n",
        "def _patched_load(*args, **kwargs):\n",
        "    if kwargs.get('load_in_4bit') and kwargs.get('quantization_config'):\n",
        "        kwargs.pop('load_in_4bit', None)\n",
        "    return _orig_load(*args, **kwargs)\n",
        "builder_module.load_pretrained_model = _patched_load\n",
        "\n",
        "# Patch 2: cache_position å‚æ•°\n",
        "from vlms.llava.model.language_model.llava_llama import LlavaLlamaForCausalLM\n",
        "_orig_forward = LlavaLlamaForCausalLM.forward\n",
        "def _patched_forward(self, *args, **kwargs):\n",
        "    kwargs.pop('cache_position', None)\n",
        "    return _orig_forward(self, *args, **kwargs)\n",
        "LlavaLlamaForCausalLM.forward = _patched_forward\n",
        "print(\"âœ… å…¼å®¹æ€§ Patch å·²åº”ç”¨\")\n",
        "\n",
        "# é‡æ–°å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from myvlm.common import VLMType, PersonalizationTask, VLM_TO_LAYER\n",
        "from configs.myvlm_art_config import MyVLMArtConfig\n",
        "from vlms.llava_wrapper import LLaVAWrapper\n",
        "from myvlm.myllava import MyLLaVA\n",
        "from concept_graph.concept_embeddings.trainer import MultiTokenEmbeddingTrainer\n",
        "\n",
        "# é…ç½®ï¼ˆæµ‹è¯•ç‰ˆï¼‰\n",
        "cfg = MyVLMArtConfig(\n",
        "    concept_name=\"dataset\",\n",
        "    concept_identifier=\"test\",\n",
        "    vlm_type=VLMType.LLAVA,\n",
        "    personalization_task=PersonalizationTask.CAPTIONING,\n",
        "    output_root=Path(\"./outputs\"),\n",
        "    data_root=Path(\"./data\"),\n",
        "    optimization_steps=3,         # Stage A + Stage B éƒ½æ˜¯ 3 ä¸ª epoch\n",
        "    learning_rate=1.0,\n",
        "    batch_size=1,                 # batch_size=1ï¼ˆStage B åŠ æƒ loss éœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰\n",
        "    reg_lambda=0.0,\n",
        "    device='cuda',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    threshold=0.75,\n",
        "    max_tokens_per_concept=2,     # æ¯ä¸ªæ¦‚å¿µ 2 ä¸ª token\n",
        "    max_concepts_per_sample=2,    # æ¯ä¸ªæ ·æœ¬ 2 ä¸ªæ¦‚å¿µ\n",
        "    backoff_delta=0.05,\n",
        "    val_subset_n=5,               # éªŒè¯ 5 ä¸ªæ ·æœ¬\n",
        "    max_reason_tokens=64,\n",
        "    use_wandb=True,\n",
        "    wandb_project=\"myvlm-art-test\",\n",
        "    wandb_run_name=\"bigger-test\",\n",
        ")\n",
        "\n",
        "# é‡æ–°åŠ è½½æ¨¡å‹\n",
        "print(\"ğŸ”„ é‡æ–°åŠ è½½ LLaVA æ¨¡å‹...\")\n",
        "vlm = LLaVAWrapper(device=cfg.device, torch_dtype=cfg.torch_dtype)\n",
        "\n",
        "print(\"ğŸ”§ åˆå§‹åŒ– MyLLaVA...\")\n",
        "myvlm = MyLLaVA(vlm, layer=VLM_TO_LAYER[cfg.vlm_type], concept_name=cfg.concept_name, cfg=cfg)\n",
        "\n",
        "print(\"ğŸ“¦ åˆ›å»º Trainer...\")\n",
        "trainer = MultiTokenEmbeddingTrainer(cfg=cfg, myvlm=myvlm, dataset_builder=None)\n",
        "\n",
        "# è¿è¡Œå®Œæ•´è®­ç»ƒï¼ˆStage A + Stage Bï¼‰\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒæµ‹è¯•...\")\n",
        "print(f\"   Stage A: {cfg.optimization_steps} epochs Ã— 86 batches\")\n",
        "print(f\"   Stage B: {cfg.optimization_steps} epochs Ã— 86 batches\")\n",
        "checkpoints = trainer.train()\n",
        "\n",
        "# ä¿å­˜\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "out_dir = cfg.output_root / cfg.concept_name / f\"seed_{cfg.seed}\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "ts = datetime.now(ZoneInfo('America/New_York')).strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = out_dir / f\"checkpoints_bigger_test_{ts}.pt\"\n",
        "torch.save(checkpoints, save_path)\n",
        "\n",
        "print(f\"\\nâœ… è®­ç»ƒæµ‹è¯•å®Œæˆ!\")\n",
        "print(f\"ğŸ’¾ æ£€æŸ¥ç‚¹: {save_path}\")\n",
        "print(f\"ğŸ“Š æŸ¥çœ‹ wandb: https://wandb.ai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone ä»£ç \n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# TODO: æ›¿æ¢ä¸ºä½ çš„ä»“åº“åœ°å€\n",
        "REPO_URL = \"https://github.com/YOUR_USERNAME/MyVLM_art.git\"\n",
        "BRANCH = \"log-for-colab\"\n",
        "\n",
        "if os.path.exists(\"/content/MyVLM_art\"):\n",
        "    shutil.rmtree(\"/content/MyVLM_art\")\n",
        "    print(\"ğŸ—‘ï¸ åˆ é™¤æ—§ä»£ç \")\n",
        "\n",
        "!git clone -b {BRANCH} {REPO_URL}\n",
        "os.chdir(\"/content/MyVLM_art\")\n",
        "print(f\"\\nğŸ“ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
        "!git log --oneline -3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Wandb ç™»å½• (å¯é€‰)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "print(\"âœ… Wandb ç™»å½•æˆåŠŸ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: è¿è¡Œè®­ç»ƒ ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== å®Œæ•´è®­ç»ƒä»£ç  ====================\n",
        "import sys\n",
        "import os\n",
        "os.chdir(\"/content/MyVLM_art\")\n",
        "sys.path.insert(0, \"/content/MyVLM_art\")\n",
        "\n",
        "# å¯¼å…¥å¹¶é…ç½®\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from myvlm.common import VLMType, PersonalizationTask, VLM_TO_LAYER\n",
        "from configs.myvlm_art_config import MyVLMArtConfig\n",
        "from vlms.llava_wrapper import LLaVAWrapper\n",
        "from myvlm.myllava import MyLLaVA\n",
        "from concept_graph.concept_embeddings.trainer import MultiTokenEmbeddingTrainer\n",
        "\n",
        "# é…ç½®å‚æ•°\n",
        "cfg = MyVLMArtConfig(\n",
        "    concept_name=\"dataset\",\n",
        "    concept_identifier=\"test\",\n",
        "    vlm_type=VLMType.LLAVA,\n",
        "    personalization_task=PersonalizationTask.CAPTIONING,\n",
        "    output_root=Path(\"./outputs\"),\n",
        "    data_root=Path(\"./data\"),\n",
        "    optimization_steps=1,         # å¿«é€Ÿæµ‹è¯•ï¼Œæ­£å¼è®­ç»ƒæ”¹ä¸º 100\n",
        "    learning_rate=1.0,\n",
        "    batch_size=1,                 # T4 å»ºè®® 1-2\n",
        "    reg_lambda=0.0,\n",
        "    device='cuda',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    threshold=0.75,\n",
        "    max_tokens_per_concept=1,\n",
        "    max_concepts_per_sample=1,\n",
        "    backoff_delta=0.05,\n",
        "    val_subset_n=3,\n",
        "    max_reason_tokens=64,\n",
        "    # Wandb (è®¾ä¸º False ç¦ç”¨)\n",
        "    use_wandb=True,\n",
        "    wandb_project=\"myvlm-art-test\",\n",
        "    wandb_run_name=\"quick-test\",\n",
        ")\n",
        "\n",
        "# è®­ç»ƒ\n",
        "print(\"ğŸ”„ åŠ è½½ LLaVA æ¨¡å‹...\")\n",
        "vlm = LLaVAWrapper(device=cfg.device, torch_dtype=cfg.torch_dtype)\n",
        "\n",
        "print(\"ğŸ”§ åˆå§‹åŒ– MyLLaVA...\")\n",
        "myvlm = MyLLaVA(vlm, layer=VLM_TO_LAYER[cfg.vlm_type], concept_name=cfg.concept_name, cfg=cfg)\n",
        "\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "trainer = MultiTokenEmbeddingTrainer(cfg=cfg, myvlm=myvlm, dataset_builder=None)\n",
        "checkpoints = trainer.train()\n",
        "\n",
        "# ä¿å­˜\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "out_dir = cfg.output_root / cfg.concept_name / f\"seed_{cfg.seed}\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "ts = datetime.now(ZoneInfo('America/New_York')).strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_path = out_dir / f\"checkpoints_{cfg.concept_name}_seed_{cfg.seed}_{ts}.pt\"\n",
        "torch.save(checkpoints, save_path)\n",
        "\n",
        "print(f\"\\nâœ… è®­ç»ƒå®Œæˆ!\")\n",
        "print(f\"ğŸ’¾ æ£€æŸ¥ç‚¹: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: ä¿å­˜åˆ° Google Drive (å¯é€‰)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = Path(\"/content/drive/MyDrive/MyVLM_art_outputs\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shutil.copytree(\"/content/MyVLM_art/outputs\", save_dir / \"outputs\", dirs_exist_ok=True)\n",
        "print(f\"âœ… å·²ä¿å­˜åˆ°: {save_dir / 'outputs'}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
